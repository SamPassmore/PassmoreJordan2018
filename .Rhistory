mean(test)
1000 /100
idx = str_detect(colnames(an_log), "q")
rates = apply(an_log[,idx], 2, median)
rates[7]
an2 = read.nexus('~/Google Drive/UniWork/varikin/language-trees/austronesian/sample_50000.trees.txt')
an_orig[[1]]$edge.length
an_orig[[1]]$edge.length * 1000
library(ape)
an_orig = read.nexus('~/Google Drive/UniWork/varikin/language-trees/austronesian/a400-m1pcv-postburnin-r8s__translated__Nodelabels_removed.trees')
an_time = lapply(an_orig, function(x) {
x$edge.length = x$edge.length * 1000
x
})
an_data = read.table('data/anc-state/austronesian.btdata')
an_data
rownames(an_data) = an_data[,1]
an_data
library(purrr)
an_sample = map(an_time[1:300], function(x){
treedata2(x, an_time)$phy
})
library(caper)
an_sample = map(an_time[1:300], function(x){
treedata2(x, an_time)$phy
})
library(geiger)
an_sample = map(an_time[1:300], function(x){
treedata2(x, an_time)$phy
})
warnings()
an_sample = map(an_time[1:300], function(x){
treedata2(x, an_data)$phy
})
warnings()
an_sample
write.nexus(an_sample, file = "../austronesian_realtime.nex")
0.000182 * 5000
0.000327 * 5000
3.901763 / 1000
(3.901763 / 1000) * 5000
an_log = read.bayestraits('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(an_log), "q")
rates = apply(an_log[,idx], 2, median)
colMeans(rates)
rates
sort(rates)
(sort(rates) / 1000) * 5000
88 / 5000
(sort(rates) / 1000) * 5000
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
(rates / (100 * 1000)) * 10000
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
(rates / (100 * 1000)) * 10000 %>%
sort()
(rates / (100 * 1000)) * 10000
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
(rates / (100 * 1000)) * 10000 %>%
sort()
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
(rates / (100 * 1000)) * 10000
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
sort((rates / (100 * 1000)) * 10000 )
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
(rates / (100 * 1000)) * 10000 %>%
sort(.)
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
sort((rates / (100 * 1000)) * 10000)
an_tree = read.nexus('./data/anc-state/austronesian.bttrees')
1000 * 100
sort((rates / constant) * 10000)
# The trees used in this analyses stated out as
# 1 = 1000 years
# And then were divided by a constant of 100 so
# 1 = 10 000
# To get this to 1 = 1 year we would need to multiply by 1000 * 100
constant = 1000 * 100
sort((rates / constant) * 10000)
devtools::install_github('SamPassmore/excdr')
kinship = read.table('data/kincodes', sep = ",")
kinship
## AN important rates are Eskimo to Hawaiian (34) &
# Hawaiian to Iroquois (45)
sort((rates / constant) * 10000)[c("q34", "q45")]
bt_log = read.bayestraits('results/anc-state/bantu/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(bt_log), "q")
rates = apply(bt_log[,idx], 2, median)
sort((rates / constant) * 10000)
kinship
ua_log = read.bayestraits('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
ua_log = read.bayestraits('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(ua_log), "q")
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
ua_log = read.bayestraits('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(ua_log), "q")
rates = apply(ua_log[,idx], 2, median)
sort((rates / constant) * 10000)
sort((rates / constant) * 10000)[c("q45", "q43", "q41")]
## AN important rates are Eskimo to Hawaiian (34) &
# Hawaiian to Iroquois (45)
sort((rates / constant) * 10000)[c("q34", "q45")]
## AN important rates are Eskimo to Hawaiian (34) &
# Hawaiian to Iroquois (45)
sort((rates / constant) * 10000)[c("q34", "q45")]
sort((rates / constant) * 10000)[c("q45", "q43", "q41")]
library(excdr)
library(stringr)
library(ape)
an_log = read.bayestraits('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(an_log), "q")
rates = apply(an_log[,idx], 2, median)
# The trees used in this analyses stated out as
# 1 = 1000 years
# And then were divided by a constant of 100 so
# 1 = 10 000
# To get this to 1 = 1 year we would need to multiply by 1000 * 100
constant = 1000 * 100
rates / 100
sort(rates / 100)
ua_tr = read.nexus('data/anc-state/utoaztecan.bttrees')
ua_tr$STATE_94430000$edge.length
ua_tr$STATE_94430000$edge.length %>% round(., 2)
ua_tr$STATE_94430000$edge.length %>% round(., 5)
plot(ua_tr$STATE_94430000)
max(ua_tr$STATE_94430000$edge.length)
max(ua_tr$STATE_94430000$edge.length) / 5000
5000 / max(ua_tr$STATE_94430000$edge.length)
bt_tr = read.nexus('data/anc-state/bantu.bttrees')
max(bt_tr$tree.555480000.61472.749694$edge.length)
(bt_tr$tree.555480000.61472.749694$edge.length)
max(bt_tr$tree.555480000.61472.749694$edge.length)
lapply(bt_tr, function(x) x$edge.length[136]) %>%
unlist() %>% mean()
unlist() %>% median()
lapply(bt_tr, function(x) x$edge.length[136]) %>%
unlist() %>% median()
x = lapply(bt_tr, function(x) x$edge.length[136]) %>%
c()
x
hist(unlist(x))
x = unlist(x)
mean(x) * 100
bt_log = read.bayestraits('results/anc-state/bantu/05-Sep-2017-16_52.Log.txt')
# The tree started out with
# 1 = 1 year
# Then divided by 100
# 1 = 100
constant = 100
idx = str_detect(colnames(bt_log), "q")
rates = apply(bt_log[,idx], 2, median)
sort((rates / constant) * 10000)
ua_tr$STATE_94430000$edge.length
ua_tr$STATE_94430000$edge.length[42]
ua_tr$STATE_94430000$edge.length[42] * 100
ua_tr$STATE_94430000$edge.length[42] * 10000
ua_tr$STATE_94430000$edge.length[42] * 100000
ua_tr$STATE_94430000$edge.length[42] * 5000
ua_tr$STATE_94430000$edge.length[42] * 50000
ua_dplace = read.nexus('https://raw.githubusercontent.com/D-PLACE/dplace-data/master/phylogenies/dunn_et_al2011_utoaztecan/posterior.trees')
ua_dplace$tree.1005000.7149.431067$edge.length
tips = ua_tr$STATE_94430000$tip.label
ua_dplace2 = geiger::treedata(ua_dplace[[1]], tips)
names(tips) = tips
ua_dplace2 = geiger::treedata(ua_dplace[[1]], tips)
plot(ua_dplace2$phy$edge.length, ua_tr$STATE_94430000$edge.length)
plot(sort(ua_dplace2$phy$edge.length), sort(ua_tr$STATE_94430000$edge.length))
plot(ua_tr[[1]])
plot(ua_tr[[1]] %>% ladderize())
plot(ua_dplace2 %>% ladderize())
plot(ua_dplace2$phy %>% ladderize())
plot(ua_dplace$tree.1005000.7149.431067)
plot(ua_dplace$tree.1005000.7149.431067 %>% ladderize())
plot(ua_dplace$tree.1005000.7149.431067)
plot(ua_dplace$tree.1005000.7149.431067)
plot(ua_dplace$tree.1010000.7142.602593)
plot(ua_dplace$tree.4985000.7147.028331)
ua_dplace$tree.4985000.7147.028331$edge.length
library(excdr)
library(stringr)
library(ape)
an_log = read.bayestraits('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(an_log), "q")
rates = apply(an_log[,idx], 2, median)
library(bayestraitr)
an_log = bt_read.log('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
library(bayestraitr)
library(stringr)
library(ape)
an_log = bt_read.log('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
library(bayestraitr)
an_log = bt_read.log('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
devtools::install_github('bayestraitr')
devtools::install_github('SamPassmore/bayestraitr')
library(bayestraitr)
an_log = bt_read.log('results/anc-state/austronesian/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(an_log), "q")
rates = apply(an_log[,idx], 2, median)
rates = apply(an_log$output[,idx], 2, median)
# The trees used in this analyses stated out as
# 1 = 1000 years
# And then were divided by a constant of 100 so
# 1 = 10 000
# To get this to 1 = 1 year we would need to multiply by 1000 * 100
constant = 1000 * 100
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
sort((rates / constant) * 10000)
idx = str_detect(colnames(an_log$output), "q")
rates = apply(an_log$output[,idx], 2, median)
# The trees used in this analyses stated out as
# 1 = 1000 years
# And then were divided by a constant of 100 so
# 1 = 10 000
# To get this to 1 = 1 year we would need to multiply by 1000 * 100
constant = 1000 * 100
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
sort((rates / constant) * 10000)
kinship = read.table('data/kincodes')
kinship
kinship = read.table('data/kincodes', sep = ",")
kinship
# Email from A. Meade says as branch lengths are doubled, rates are halved
# In this case branch lengths have been reduced by constant, therefore rates should increase by that constant
# So to get rates to equate to branch lengths they need to be divided by the constant and then multiplied by years?
sort((rates / constant) * 10000)
kinship
## AN important rates are Eskimo to Hawaiian (34) &
# Hawaiian to Iroquois (45)
sort((rates / constant) * 10000)[c("q34", "q45")]
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
ua_log = read.bayestraits('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
ua_log = bt_read.log('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
ua_tr = read.nexus('data/anc-state/utoaztecan.bttrees')
ua_dplace = read.nexus('https://raw.githubusercontent.com/D-PLACE/dplace-data/master/phylogenies/dunn_et_al2011_utoaztecan/posterior.trees')
tips = ua_tr$STATE_94430000$tip.label
names(tips) = tips
ua_dplace2 = geiger::treedata(ua_dplace[[1]], tips)
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/.Log.txt')
ua_log$output %>% head()
idx = str_detect(colnames(ua_log$output), "q")
colMeans(ua_log$output[,idx])
colMeans(ua_log$output[,idx]) %>% sort()
colMeans(ua_log$output[,idx]) %>% sort(.)
rates = apply(ua_log$outpu[,idx], 2, median)
sort((rates / constant) * 10000)
#ua_tr = read.nexus('data/anc-state/utoaztecan.bttrees')
ua_tr = read.nexus('../terminology-anc-state/data/utoaztecan-2.bttrees')
ua_dplace = read.nexus('https://raw.githubusercontent.com/D-PLACE/dplace-data/master/phylogenies/dunn_et_al2011_utoaztecan/posterior.trees')
ua_tr[[1]]$edge.length
ua_dplace[[1]]$edge.length
ua_tr[[1]]$edge.length
ua_dplace[[1]]$edge.length[42]
ua_dplace[[1]]$edge.length
ua_dplace[[1]]$edge.length[66]
ua_tr[[1]]$edge.length[42]
ua_dplace[[1]]$edge.length[66]
ua_tr[[1]]$edge.length[42] / 100
ua_tr[[1]]$edge.length[42] 8 100
ua_tr[[1]]$edge.length[42]
ua_dplace[[1]]$edge.length[66] * 100
ua_dplace[[1]]$edge.length[66] / 100
ua_dplace[[1]]$edge.length[66]
# The dplace tree is
# 1 = 1000 years
# Then I divided by 100 so
# 1 = 10 000 years
# So to go back
constant = 100 * 1000
idx = str_detect(colnames(ua_log), "q")
idx = str_detect(colnames(ua_log$output), "q")
rates = apply(ua_log$output[,idx], 2, median)
sort((rates / constant) * 10000)
sort((rates / constant) * 10000)[c("q45", "q43", "q41")]
rates
constant
sort((rates / constant) * 10000) %>% sort(.)
sort((rates / constant) * 10000)[c("q45", "q43", "q41")] %>%
sort(.)
rates
hist(ua_log$output$q45)
hist(ua_log$output$q43)
hist(ua_log$output$q41)
kinship
sum(ua_log$output$q41 > 0.05)
sum(ua_log$output$q41 < 0.05)
sum(ua_log$output$q41 > 0.05) / nrow(ua_log$output)
idx = ua_log$output$q41 > 0.05
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
ua_log = bt_read.log('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
ua_tr[[1]]$edge.length[42]
ua_dplace[[1]]$edge.length[66] / 100
ua_tr = read.nexus('data/anc-state/utoaztecan.bttrees')
ua_tr[[1]]$edge.length[42]
ua_dplace[[1]]$edge.length[66] / 100
ua_tr[[1]]$edge.length
ua_tr[[1]]$edge.length[42]
ua_tr[[1]]$edge.length[9]
ua_tr[[1]]$edge.length %>% max()
idx = str_detect(colnames(bt_log), "Root")
idx = str_detect(colnames(ua_log$output), "Root")
apply(ua_log$output[,idx], 2, median)
kinship
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
#ua_log = bt_read.log('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/.Log.txt')
idx = str_detect(colnames(ua_log$output), "Root")
apply(ua_log$output[,idx], 2, median)
hist(ua_log$output[,"Root P(4)"])
idx = str_detect(colnames(ua_log$output), "q")
rates = apply(ua_log$output[,idx], 2, median)
sort((rates / constant) * 10000) %>% sort(.)
sort((rates / constant) * 10000)[c("q45", "q43", "q41")] %>%
sort(.)
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
ua_log = bt_read.log('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
idx = str_detect(colnames(ua_log$output), "q")
rates = apply(ua_log$output[,idx], 2, median)
sort((rates / constant) * 10000) %>% sort(.)
sort((rates / constant) * 10000)[c("q45", "q43", "q41")] %>%
sort(.)
sort((rates / constant) * 10000)
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
#ua_log = bt_read.log('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/.Log.txt')
ua_tr = read.nexus('data/anc-state/utoaztecan.bttrees')
ua_tr$STATE_94430000$edge.length %>% max()
ua_tr$STATE_94430000$edge.length %>% max() * 1000
ua_tr$STATE_94430000$edge.length %>% max() * 100000
ua_tr$STATE_94430000$edge.length %>% max() * 1000000
## UA important rates were Hawaiian to Iroquois (45),
# Hawaiian to Eskimo (43) & Hawaiian to Crow (41)
#ua_log = bt_read.log('results/anc-state/utoaztecan/05-Sep-2017-16_52.Log.txt')
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/.Log.txt')
#ua_tr = read.nexus('data/anc-state/utoaztecan.bttrees')
ua_tr = read.nexus('../terminology-anc-state/data/utoaztecan-2.bttrees')
ua_dplace = read.nexus('https://raw.githubusercontent.com/D-PLACE/dplace-data/master/phylogenies/dunn_et_al2011_utoaztecan/posterior.trees')
# If I use the new analyses w/ the DPLACE tree
# The dplace tree is
# 1 = 1000 years
# Then I divided by 100 so
# 1 = 10 000 years
# So to go back
constant = 100 * 1000
idx = str_detect(colnames(ua_log$output), "q")
rates = apply(ua_log$output[,idx], 2, median)
sort((rates / constant) * 10000) %>% sort(.)
sort((rates / constant) * 10000)[c("q45", "q43", "q41")] %>%
sort(.)
#ua = read.bayestraits('results/anc-state/utoaztecan/26-Oct-2017-09_54.Log.txt')
ua = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/.Log.txt')
plot(ua$output$Lh, type = 'l')
modelstring_frequencies = function(results){
# get column names
cn_results = colnames(results)
# find transition columns
#q = results[,str_detect(cn_results, "q")]
# get model string and seperate it out
ms = results$`Model string` %>%
str_remove('[\']') %>%
trimws() %>%
str_split('\\s') %>%
do.call(rbind, .)
# then get counts of estimates for each parameter
ms2 = list()
for(i in 1:ncol(ms)){
ms2[[i]] = table(ms[,i])
}
# possible states for this lang-fam
states = lapply(ms2, names) %>%
unlist() %>%
unique() %>%
sort()
# build a matrix of posible states
occurances = matrix(NA, nrow = length(ms2), ncol = length(states))
dimnames(occurances) = list(cn_results[str_detect(cn_results, "q")], states)
# fill matrix
for(i in seq_along(ms2)){
row = ms2[[i]]
occurances[i,names(row)] = row
}
occurances
}
ua_ms = modelstring_frequencies(tail(ua, 10000))
ua_ms = modelstring_frequencies(tail(ua$output, 10000))
ua_ms
hist(ua_log$output$`Global Rate`)
plot(ua_log$output$`Global Rate`)
plot(ua_log$output$`Global Rate`, type = "l")
plot(ua_log$output$`Global Rate`)
plot(ua_log$output$`Global Rate` %>% sort(.))
ua_log$output$`Global Rate` / constant %>%
mean(.)
mean(ua_log$output$`Global Rate` / constant)
median(ua_log$output$`Global Rate` / constant)
median(ua_log$output$`Global Rate` / constant) * 10000
## global rates
library(bayestraitr)
an_log = bt_read.log('../terminology-anc-state/bt-output/austronesian/27-Nov-2018-16_43.Log.txt')
an_log = bt_read.log('../terminology-anc-state/bt-output/austronesian/27-Nov-2018-16_43.Log.txt')
median(an_log$output$`Global Rate` / constant) * 10000
bt_log = bt_read.log('../terminology-anc-state/bt-output/bantu/27-Nov-2018-16_43.Log.txt')
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/27-Nov-2018-16_44.Log.txt')
median(ua_log$output$`Global Rate` / constant) * 10000
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/27-Nov-2018-16_44.Log.txt')
median(ua_log$output$`Global Rate` / constant) * 10000
ua_log$output
ua_log$output$`Global Rate` == an_log$output$`Global Rate`
ua_log$output$`Global Rate`[1] == an_log$output$`Global Rate`[1]
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/27-Nov-2018-16_44.Log.txt')
ua_log$output$`Global Rate`[1]
an_log$output$`Global Rate`[1]
mean(an_log$output$`Global Rate`)
mean(ua_log$output$`Global Rate`)
median(ua_log$output$`Global Rate`)
median(an_log$output$`Global Rate`)
median(ua_log$output$`Global Rate` / constant) * 10000
bt_log = bt_read.log('../terminology-anc-state/bt-output/bantu/27-Nov-2018-16_43.Log.txt')
median(bt_log$output$`Global Rate` / constant) * 10000
bt_dplace = read.nexus('https://raw.githubusercontent.com/D-PLACE/dplace-data/master/phylogenies/dunn_et_al2011_utoaztecan/posterior.trees')
bt_tr = read.nexus('data/anc-state/bantu.bttrees')
bt_tr$tree.555480000.61472.749694$edge.length %>% max()
bt_tr$tree.555480000.61472.749694$edge.length %>% max(.)
bt_dplace$tree.1005000.7149.431067$edge.length %>% max(.)
# original tree is 1 = 100 years
# the is divided by 100
# so constant is
constant = 100 * 100
median(bt_log$output$`Global Rate` / constant) * 10000
median(bt_log$output$`Global Rate` / constant)
median(bt_log$output$`Global Rate`)
median(bt_log$output$`Global Rate`) / constant
(median(bt_log$output$`Global Rate`) / constant)  * 10000
bt_tr = read.nexus('data/anc-state/bantu.bttrees')
bt_tr$tree.555480000.61472.749694$edge.length %>% max(.)
75 * 100
## global rates
library(bayestraitr)
constant = 100 * 1000 # divided by 100 after starting with 1 = 1000
an_log = bt_read.log('../terminology-anc-state/bt-output/austronesian/27-Nov-2018-16_43.Log.txt')
median(an_log$output$`Global Rate` / constant) * 10000
bt_log = bt_read.log('../terminology-anc-state/bt-output/bantu/27-Nov-2018-16_43.Log.txt')
median(bt_log$output$`Global Rate` / constant) * 10000
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/27-Nov-2018-16_44.Log.txt')
median(ua_log$output$`Global Rate` / constant) * 10000
10000 / 8.224336
ua_log = bt_read.log('../terminology-anc-state/bt-output/utoaztecan/.Log.txt')
median(ua_log$output$`Global Rate` / constant) * 10000
library(excdr)
library(stringr)
library(dplyr)
library(tidyr)
modelstring_frequencies = function(results){
# get column names
cn_results = colnames(results)
# find transition columns
#q = results[,str_detect(cn_results, "q")]
# get model string and seperate it out
ms = results$`Model string` %>%
str_remove('[\']') %>%
trimws() %>%
str_split('\\s') %>%
do.call(rbind, .)
# then get counts of estimates for each parameter
ms2 = list()
for(i in 1:ncol(ms)){
ms2[[i]] = table(ms[,i])
}
# possible states for this lang-fam
states = lapply(ms2, names) %>%
unlist() %>%
unique() %>%
sort()
# build a matrix of posible states
occurances = matrix(NA, nrow = length(ms2), ncol = length(states))
dimnames(occurances) = list(cn_results[str_detect(cn_results, "q")], states)
# fill matrix
for(i in seq_along(ms2)){
row = ms2[[i]]
occurances[i,names(row)] = row
}
occurances
}
an = read.bayestraits(filename = 'results/anc-state/austronesian/26-Oct-2017-09_53.Log.txt')
# check mcmc chain
plot(tail(an$Lh, 10000), type = 'l')
# seems fine
an_ms = modelstring_frequencies(tail(an, 10000))
